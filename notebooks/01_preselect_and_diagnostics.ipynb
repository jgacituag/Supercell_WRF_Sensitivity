{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7853ac7b",
   "metadata": {},
   "source": [
    "# 01 – Preselect & Diagnostics (CAPE / CIN / Shear)\n",
    "This notebook **does not run WRF**. It reads soundings from your Sobol experiment, computes diagnostics (CAPE, CIN, 0–1 km and 0–6 km bulk shear, PW), and visualizes **ranges and coverage**.\n",
    "\n",
    "**Modes:**\n",
    "1. *Generate mode*: Generate soundings on-the-fly using Sobol samples\n",
    "2. *Folder mode*: Read existing WRF-ready `input_sounding_*` files from step2 output\n",
    "3. *Diagnostics mode*: Load pre-computed diagnostics from step2\n",
    "\n",
    "The goal is to explore **full distributions** – not just a low‑CAPE/high‑shear subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bff85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# Add src to path\n",
    "REPO_ROOT = Path.cwd().parents[0] if (Path.cwd().name == 'notebooks') else Path.cwd()\n",
    "SRC = REPO_ROOT / 'src'\n",
    "sys.path.insert(0, str(SRC))\n",
    "\n",
    "# Import your sounding generator\n",
    "from sounding_generator import (\n",
    "    generate_sounding,\n",
    "    calculate_cape_cin,\n",
    "    read_input_sounding as read_wrf_sounding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231cf08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "MODE = 'folder'   # 'generate', 'folder', or 'diagnostics'\n",
    "\n",
    "# For 'generate' mode: path to your Sobol experiment\n",
    "EXPERIMENT_DIR = str(REPO_ROOT / 'outputs' / 'sobol_exp_500')\n",
    "BASE_SOUNDING = str(SRC / 'input_sounding')  # Your base sounding file\n",
    "N_SAMPLES = 500  # How many samples to generate (for testing)\n",
    "\n",
    "# For 'folder' mode: directory with input_sounding_* files\n",
    "SOUNDINGS_DIR = str(REPO_ROOT / 'outputs' / 'sobol_exp_500' / 'soundings')\n",
    "\n",
    "# For 'diagnostics' mode: path to diagnostics.pkl from step2\n",
    "DIAGNOSTICS_PKL = str(REPO_ROOT / 'outputs' / 'sobol_exp_500' / 'soundings' / 'diagnostics.pkl')\n",
    "\n",
    "# Output\n",
    "OUT_CATALOG = str(REPO_ROOT / 'outputs' / 'env_catalog.csv')\n",
    "os.makedirs(Path(OUT_CATALOG).parent, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute_diagnostics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diagnostics(sounding):\n",
    "    \"\"\"Compute diagnostics for a sounding dict.\"\"\"\n",
    "    \n",
    "    # CAPE and CIN\n",
    "    cape, cin = calculate_cape_cin(sounding)\n",
    "    \n",
    "    # Shear at different levels\n",
    "    def get_shear(z_target):\n",
    "        idx = np.argmin(np.abs(sounding['height'] - z_target))\n",
    "        return np.sqrt((sounding['u'][idx] - sounding['u'][0])**2 +\n",
    "                      (sounding['v'][idx] - sounding['v'][0])**2)\n",
    "    \n",
    "    sh01 = get_shear(1000)\n",
    "    sh03 = get_shear(3000)\n",
    "    sh06 = get_shear(6000)\n",
    "    \n",
    "    # Precipitable water\n",
    "    pwat = 0\n",
    "    for j in range(1, len(sounding['height'])):\n",
    "        dz = sounding['height'][j] - sounding['height'][j-1]\n",
    "        qv_avg = (sounding['qv'][j] + sounding['qv'][j-1]) / 2 / 1000  # Convert g/kg to kg/kg\n",
    "        p_avg = (sounding['p'][j] + sounding['p'][j-1]) / 2 * 100  # Convert hPa to Pa\n",
    "        t_avg = (sounding['t'][j] + sounding['t'][j-1]) / 2\n",
    "        rho = p_avg / (287 * t_avg)\n",
    "        pwat += rho * qv_avg * dz\n",
    "    \n",
    "    return {\n",
    "        'MLCAPE': cape,\n",
    "        'MLCIN': cin,\n",
    "        'SH01': sh01,\n",
    "        'SH03': sh03,\n",
    "        'SH06': sh06,\n",
    "        'PW': pwat\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a231656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build diagnostics catalog ---\n",
    "rows = []\n",
    "\n",
    "if MODE == 'generate':\n",
    "    print(f\"Generating {N_SAMPLES} soundings from Sobol samples...\")\n",
    "    \n",
    "    # Load Sobol experiment\n",
    "    with open(f'{EXPERIMENT_DIR}/problem.pkl', 'rb') as f:\n",
    "        problem = pickle.load(f)\n",
    "    param_values = np.load(f'{EXPERIMENT_DIR}/param_values.npy')\n",
    "    \n",
    "    # Generate subset of soundings\n",
    "    n_process = min(N_SAMPLES, len(param_values))\n",
    "    for i in range(n_process):\n",
    "        param_dict = dict(zip(problem['names'], param_values[i]))\n",
    "        \n",
    "        try:\n",
    "            sounding = generate_sounding(param_dict, base_sounding_file=BASE_SOUNDING)\n",
    "            diag = compute_diagnostics(sounding)\n",
    "            rows.append({'idx': i, **diag})\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"  Progress: {i+1}/{n_process}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: Sample {i} failed: {e}\")\n",
    "            rows.append({'idx': i, 'MLCAPE': np.nan, 'MLCIN': np.nan, \n",
    "                        'SH01': np.nan, 'SH03': np.nan, 'SH06': np.nan, 'PW': np.nan})\n",
    "\n",
    "elif MODE == 'folder':\n",
    "    print(f\"Reading soundings from {SOUNDINGS_DIR}...\")\n",
    "    files = sorted(glob.glob(os.path.join(SOUNDINGS_DIR, 'input_sounding_*')))\n",
    "    if not files:\n",
    "        raise SystemExit(f'No input_sounding_* files found in {SOUNDINGS_DIR}')\n",
    "    \n",
    "    print(f\"Found {len(files)} sounding files\")\n",
    "    for i, fp in enumerate(files):\n",
    "        try:\n",
    "            sounding = read_wrf_sounding(fp)\n",
    "            diag = compute_diagnostics(sounding)\n",
    "            rows.append({'idx': i, **diag})\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"  Progress: {i+1}/{len(files)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: File {fp} failed: {e}\")\n",
    "            rows.append({'idx': i, 'MLCAPE': np.nan, 'MLCIN': np.nan,\n",
    "                        'SH01': np.nan, 'SH03': np.nan, 'SH06': np.nan, 'PW': np.nan})\n",
    "\n",
    "elif MODE == 'diagnostics':\n",
    "    print(f\"Loading pre-computed diagnostics from {DIAGNOSTICS_PKL}...\")\n",
    "    with open(DIAGNOSTICS_PKL, 'rb') as f:\n",
    "        diag_dict = pickle.load(f)\n",
    "    \n",
    "    # Convert to format expected by notebook\n",
    "    for i in range(len(diag_dict['sample_id'])):\n",
    "        rows.append({\n",
    "            'idx': diag_dict['sample_id'][i],\n",
    "            'MLCAPE': diag_dict['cape'][i],\n",
    "            'MLCIN': diag_dict['cin'][i],\n",
    "            'SH01': diag_dict['shear_0_1km'][i],\n",
    "            'SH03': diag_dict['shear_0_3km'][i],\n",
    "            'SH06': diag_dict['shear_0_6km'][i],\n",
    "            'PW': diag_dict['pwat'][i]\n",
    "        })\n",
    "\n",
    "else:\n",
    "    raise ValueError(f'Unknown MODE: {MODE}')\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(OUT_CATALOG, index=False)\n",
    "print(f\"\\nSaved catalog to {OUT_CATALOG}\")\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40da710",
   "metadata": {},
   "source": [
    "## Distributions – CAPE, |CIN|, and Shear\n",
    "These give you the **ranges** covered by your design. CIN is plotted as absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['MLCAPE','MLCIN','SH01','SH03','SH06','PW']:\n",
    "    if col not in df.columns: \n",
    "        continue\n",
    "    vals = np.abs(df[col]) if col=='MLCIN' else df[col]\n",
    "    vals_clean = vals.dropna()\n",
    "    \n",
    "    if len(vals_clean) == 0:\n",
    "        print(f\"No valid data for {col}\")\n",
    "        continue\n",
    "    \n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.hist(vals_clean.values, bins=40, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel(col if col!='MLCIN' else '|MLCIN| (J/kg)', fontsize=11)\n",
    "    plt.ylabel('Count', fontsize=11)\n",
    "    plt.title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_val = vals_clean.mean()\n",
    "    median_val = vals_clean.median()\n",
    "    plt.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.1f}')\n",
    "    plt.axvline(median_val, color='orange', linestyle='--', linewidth=2, label=f'Median: {median_val:.1f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"{col}: min={vals_clean.min():.1f}, mean={mean_val:.1f}, max={vals_clean.max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5968e064",
   "metadata": {},
   "source": [
    "## 2‑D Coverage (hexbin)\n",
    "Quick maps to see where samples land: **CAPE vs shear**, and **CAPE vs |CIN|**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc85611",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    ('MLCAPE','SH06','CAPE vs 0–6 km shear'),\n",
    "    ('MLCAPE','SH01','CAPE vs 0–1 km shear'),\n",
    "    ('MLCAPE','MLCIN','CAPE vs |CIN|'),\n",
    "    ('SH06','SH01','0–6 km shear vs 0–1 km shear'),\n",
    "]\n",
    "\n",
    "for x, y, title in pairs:\n",
    "    if x not in df or y not in df: \n",
    "        continue\n",
    "    \n",
    "    xv = df[x].values\n",
    "    yv = np.abs(df[y].values) if y=='MLCIN' else df[y].values\n",
    "    \n",
    "    # Remove NaN\n",
    "    mask = ~(np.isnan(xv) | np.isnan(yv))\n",
    "    xv = xv[mask]\n",
    "    yv = yv[mask]\n",
    "    \n",
    "    if len(xv) == 0:\n",
    "        print(f\"No valid data for {title}\")\n",
    "        continue\n",
    "    \n",
    "    plt.figure(figsize=(7,6))\n",
    "    hb = plt.hexbin(xv, yv, gridsize=40, mincnt=1, cmap='YlOrRd')\n",
    "    plt.xlabel(x if x!='MLCIN' else '|MLCIN| (J/kg)', fontsize=11)\n",
    "    plt.ylabel(y if y!='MLCIN' else '|MLCIN| (J/kg)', fontsize=11)\n",
    "    plt.title(title, fontsize=12, fontweight='bold')\n",
    "    cb = plt.colorbar(hb, label='Count')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25938f47",
   "metadata": {},
   "source": [
    "## Binned coverage tables\n",
    "Adjust bins as needed for your parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f756c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins\n",
    "cape_bins = [0, 500, 1000, 2000, 3000, 4000, np.inf]\n",
    "shear_bins = [0, 10, 15, 20, 25, 30, 40, np.inf]\n",
    "cin_bins = [0, 25, 50, 75, 100, 150, np.inf]\n",
    "\n",
    "# Create binned columns\n",
    "df['CINabs'] = np.abs(df['MLCIN'])\n",
    "df['CAPE_bin'] = pd.cut(df['MLCAPE'], bins=cape_bins)\n",
    "df['SH06_bin'] = pd.cut(df['SH06'], bins=shear_bins)\n",
    "df['CIN_bin'] = pd.cut(df['CINabs'], bins=cin_bins)\n",
    "\n",
    "# Create pivot tables\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CAPE vs 0-6 km Shear Coverage\")\n",
    "print(\"=\"*60)\n",
    "pivot_cape_sh06 = df.pivot_table(\n",
    "    index='CAPE_bin', \n",
    "    columns='SH06_bin', \n",
    "    values='idx', \n",
    "    aggfunc='count',\n",
    "    observed=False\n",
    ").fillna(0).astype(int)\n",
    "print(pivot_cape_sh06)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CAPE vs |CIN| Coverage\")\n",
    "print(\"=\"*60)\n",
    "pivot_cape_cin = df.pivot_table(\n",
    "    index='CAPE_bin', \n",
    "    columns='CIN_bin', \n",
    "    values='idx', \n",
    "    aggfunc='count',\n",
    "    observed=False\n",
    ").fillna(0).astype(int)\n",
    "print(pivot_cape_cin)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Summary Statistics\")\n",
    "print(\"=\"*60)\n",
    "total_samples = len(df)\n",
    "valid_samples = df['MLCAPE'].notna().sum()\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Valid samples: {valid_samples} ({valid_samples/total_samples*100:.1f}%)\")\n",
    "print(f\"Failed samples: {total_samples - valid_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d_scatter",
   "metadata": {},
   "source": [
    "## 3D Scatter: CAPE vs Shear vs |CIN|\n",
    "Visualize the full 3D parameter space coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Clean data\n",
    "mask = df['MLCAPE'].notna() & df['SH06'].notna() & df['MLCIN'].notna()\n",
    "df_clean = df[mask].copy()\n",
    "\n",
    "if len(df_clean) > 0:\n",
    "    fig = plt.figure(figsize=(14,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Main 3D scatter\n",
    "    scatter = ax.scatter(\n",
    "        df_clean['MLCAPE'], \n",
    "        df_clean['SH06'], \n",
    "        df_clean['CINabs'],\n",
    "        c=df_clean['CINabs'], \n",
    "        cmap='viridis',\n",
    "        marker='o', \n",
    "        s=20, \n",
    "        alpha=0.6\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('MLCAPE (J/kg)', fontsize=11)\n",
    "    ax.set_ylabel('0-6 km Shear (m/s)', fontsize=11)\n",
    "    ax.set_zlabel('|MLCIN| (J/kg)', fontsize=11)\n",
    "    ax.set_title('3D Parameter Space: CAPE vs Shear vs |CIN|', fontsize=13, fontweight='bold')\n",
    "    \n",
    "    # Set reasonable axis limits\n",
    "    ax.set_xlim(df_clean['MLCAPE'].min() - 200, df_clean['MLCAPE'].max() + 200)\n",
    "    ax.set_ylim(0, df_clean['SH06'].max() + 5)\n",
    "    ax.set_zlim(0, df_clean['CINabs'].max() + 10)\n",
    "    \n",
    "    # Projections on walls\n",
    "    ax.scatter(\n",
    "        df_clean['MLCAPE'], \n",
    "        df_clean['SH06'], \n",
    "        zs=0, \n",
    "        zdir='z', \n",
    "        c='lightcoral', \n",
    "        marker='.', \n",
    "        s=5, \n",
    "        alpha=0.3\n",
    "    )\n",
    "    ax.scatter(\n",
    "        df_clean['MLCAPE'], \n",
    "        zs=df_clean['SH06'].max() + 5, \n",
    "        zdir='y', \n",
    "        ys=df_clean['CINabs'], \n",
    "        c='lightgreen', \n",
    "        marker='.', \n",
    "        s=5, \n",
    "        alpha=0.3\n",
    "    )\n",
    "    ax.scatter(\n",
    "        zs=df_clean['MLCAPE'].min() - 200, \n",
    "        zdir='x', \n",
    "        xs=df_clean['SH06'], \n",
    "        ys=df_clean['CINabs'], \n",
    "        c='lightblue', \n",
    "        marker='.', \n",
    "        s=5, \n",
    "        alpha=0.3\n",
    "    )\n",
    "    \n",
    "    plt.colorbar(scatter, label='|CIN| (J/kg)', shrink=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No valid data for 3D plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis_summary",
   "metadata": {},
   "source": [
    "## Analysis Summary\n",
    "Key metrics and coverage assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PARAMETER SPACE COVERAGE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "valid_df = df.dropna(subset=['MLCAPE', 'MLCIN', 'SH06'])\n",
    "\n",
    "if len(valid_df) > 0:\n",
    "    print(f\"\\nValid samples: {len(valid_df)}\")\n",
    "    print(\"\\nParameter Ranges:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    params = [\n",
    "        ('MLCAPE', 'J/kg'),\n",
    "        ('|MLCIN|', 'J/kg'),\n",
    "        ('0-1 km Shear', 'm/s'),\n",
    "        ('0-6 km Shear', 'm/s'),\n",
    "        ('Precip Water', 'mm')\n",
    "    ]\n",
    "    \n",
    "    cols = ['MLCAPE', 'CINabs', 'SH01', 'SH06', 'PW']\n",
    "    \n",
    "    for (name, unit), col in zip(params, cols):\n",
    "        if col in valid_df.columns:\n",
    "            vals = valid_df[col]\n",
    "            print(f\"{name:20s}: {vals.min():7.1f} to {vals.max():7.1f} {unit:6s} \"\n",
    "                  f\"(mean: {vals.mean():7.1f})\")\n",
    "    \n",
    "    # Identify potentially interesting cases\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Potentially Interesting Cases:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    high_cape_high_shear = valid_df[(valid_df['MLCAPE'] > 2000) & (valid_df['SH06'] > 20)]\n",
    "    low_cin = valid_df[valid_df['CINabs'] < 25]\n",
    "    extreme_shear = valid_df[valid_df['SH06'] > 30]\n",
    "    \n",
    "    print(f\"High CAPE + High Shear (>2000 J/kg, >20 m/s): {len(high_cape_high_shear)} samples\")\n",
    "    print(f\"Low CIN (<25 J/kg): {len(low_cin)} samples\")\n",
    "    print(f\"Extreme shear (>30 m/s): {len(extreme_shear)} samples\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "else:\n",
    "    print(\"No valid samples to analyze!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrf-sensitivity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
